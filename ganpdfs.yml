#############################################################################################
# PDF Grids:                                                                                #
# ---------                                                                                 #
# * Inittial scale q (in GeV)                                                               #
# * Options for x-grid:                                                                     #
#   - custom: Custom GANs xgrid as defined in the Module                                    #
#   - lhapdf: Use the same xgrid as in the input PDF                                        #
#############################################################################################
q        : 1.65                                      # Initial q0 value (in GeV)
x_grid   : standard                                  # x-grid format. Options: standard, custom, lhapdf

#############################################################################################
# GAN setup:                                                                                #
# ---------                                                                                 #
# * Options for architecture:                                                               #
#   - dnn : Deep Neural Network                                                             #
#   - dcnn: Deep Convolutional Neural Network                                               #
#############################################################################################
use_saved_model       : False                        # Skip training and use pre-trained generator model
                                                     # All the parameters below will be skipped is set to TRUE

architecture          : cnn                          # Architecture model. Options: cnn, dnn

gan_parameters:
  optimizer:
    optimizer_name    : RMSprop                      # options: SGD, Adam, RMSprop, Adadelta
    learning_rate     : 0.00005                      # Learning rate for the optimizer class

gen_parameters:
  size_networks       : 1                            # number of hidden layers
  number_nodes        : 128                          # number of nodes in the first layer
  use_bias            : False                        # if True add biases to the Layers
  bias_initializer    : zeros                        # list of initializer classes: https://keras.io/api/layers/initializers/
  kernel_initializer  : glorot_uniform               # list of initializer classes: https://keras.io/api/layers/initializers/
  optimizer:
    optimizer_name    : RMSprop                      # options: SGD, Adam, RMSprop, Adadelta
    learning_rate     : 0.00005                      # learning rate for the optimizer class
  loss                : binary_crossentropy          # options: all tf.keras losses + wasserstein
  activation          : leakyrelu                    # options: relu, leakyrelu, elu

disc_parameters:
  size_networks       : 1                            # number of hidden layers
  number_nodes        : 450                          # number of nodes in the first layer
  use_bias            : False                        # if True add biases to the Layers
  bias_initializer    : zeros                        # list of initializer classes: https://keras.io/api/layers/initializers/
  kernel_initializer  : glorot_uniform               # list of initializer classes: https://keras.io/api/layers/initializers/
  weights_constraints : 1                            # Constrain weights values
  optimizer:
    optimizer_name    : RMSprop                      # options: SGD, Adam, RMSprop, Adadelta
    learning_rate     : 0.00005                      # learning rate for the optimizer class
  loss                : binary_crossentropy          # options: all tf.keras losses + wasserstein
  activation          : leakyrelu                    # options: relu, leakyrelu, elu

ConvoluteOutput       : False

#############################################################################################
# Training Setup:                                                                           #
# --------------                                                                            #
# * batch size                                                                              #
# * {i}_steps: number of steps to train a {i}={generator, discriminator/critic} at each     #
#   iteration.                                                                              #
#############################################################################################
nd_steps   : 4                                       # Number of steps to train the Discriminator for one training run
ng_steps   : 3                                       # Number of steps to train the Generator for one training run
batch_size : 70                                      # Batch size per epoch in terms of percentage
epochs     : 600                                     # Number of epochs
